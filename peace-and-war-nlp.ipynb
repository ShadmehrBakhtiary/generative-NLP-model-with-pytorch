{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMTO3CtKvb7WRGM5mlcLywD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yle0j4ZRqWM-","executionInfo":{"status":"ok","timestamp":1716841578722,"user_tz":-210,"elapsed":26818,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"55330275-69c7-4389-c038-d532c45cf007"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["import liabraries"],"metadata":{"id":"8QvcQL5pr0Ex"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"metadata":{"id":"QEUu9p-drKFC","executionInfo":{"status":"ok","timestamp":1716841585728,"user_tz":-210,"elapsed":3633,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\n","with open('/content/drive/MyDrive/ML_FOLDER/ai-project/nlp-generative-novel/war_and_peace.txt','r',encoding='utf8') as f:\n","    text = f.read()"],"metadata":{"id":"bOXOSUrFqoca","executionInfo":{"status":"ok","timestamp":1716841587381,"user_tz":-210,"elapsed":1655,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(text[:2000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"322t4ZmIrkzT","executionInfo":{"status":"ok","timestamp":1716841587381,"user_tz":-210,"elapsed":7,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"cabedd25-acb7-4e08-9814-26e0a8392b7d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["WAR AND PEACE\n","\n","BOOK ONE: 1805\n","\n","\n","CHAPTER I\n","\n","“Well, Prince, so Genoa and Lucca are now just family estates of the\n","Buonapartes. But I warn you, if you don’t tell me that this means war,\n","if you still try to defend the infamies and horrors perpetrated by that\n","Antichrist—I really believe he is Antichrist—I will have nothing\n","more to do with you and you are no longer my friend, no longer my\n","‘faithful slave,’ as you call yourself! But how do you do? I see I\n","have frightened you—sit down and tell me all the news.”\n","\n","It was in July, 1805, and the speaker was the well-known Anna Pávlovna\n","Schérer, maid of honor and favorite of the Empress Márya Fëdorovna.\n","With these words she greeted Prince Vasíli Kurágin, a man of high\n","rank and importance, who was the first to arrive at her reception. Anna\n","Pávlovna had had a cough for some days. She was, as she said, suffering\n","from la grippe; grippe being then a new word in St. Petersburg, used\n","only by the elite.\n","\n","All her invitations without exception, written in French, and delivered\n","by a scarlet-liveried footman that morning, ran as follows:\n","\n","“If you have nothing better to do, Count (or Prince), and if the\n","prospect of spending an evening with a poor invalid is not too terrible,\n","I shall be very charmed to see you tonight between 7 and 10—Annette\n","Schérer.”\n","\n","“Heavens! what a virulent attack!” replied the prince, not in the\n","least disconcerted by this reception. He had just entered, wearing an\n","embroidered court uniform, knee breeches, and shoes, and had stars on\n","his breast and a serene expression on his flat face. He spoke in that\n","refined French in which our grandfathers not only spoke but thought, and\n","with the gentle, patronizing intonation natural to a man of importance\n","who had grown old in society and at court. He went up to Anna Pávlovna,\n","kissed her hand, presenting to her his bald, scented, and shining head,\n","and complacently seated himself on the sofa.\n","\n","“First of all, dear friend, tell me how you are. Set your friend’s\n","mind at rest,” said he wi\n"]}]},{"cell_type":"code","source":["len(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R7hazDCFr4Xf","executionInfo":{"status":"ok","timestamp":1716841587382,"user_tz":-210,"elapsed":6,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"d97b909f-4256-4c66-fd5a-3d26ba789acb"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3201623"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# **Encode Entire Text**"],"metadata":{"id":"ztz6nfrqr9tf"}},{"cell_type":"code","source":["all_characters = set(text)\n","decoder = dict(enumerate(all_characters))\n","decoder.items()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eK2VnxgYr_u-","executionInfo":{"status":"ok","timestamp":1716841587931,"user_tz":-210,"elapsed":553,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"1c98cf23-e607-4ae3-b9e5-fa3dad5c2a17"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_items([(0, 'w'), (1, 'œ'), (2, 'M'), (3, 'e'), (4, 'D'), (5, 'í'), (6, '1'), (7, '9'), (8, 'b'), (9, 'ï'), (10, 'I'), (11, 'l'), (12, 'B'), (13, 'H'), (14, 'W'), (15, 'L'), (16, 'ý'), (17, 'ô'), (18, 'q'), (19, 'c'), (20, '2'), (21, '4'), (22, '('), (23, '6'), (24, 'F'), (25, 'r'), (26, 't'), (27, 'J'), (28, 'j'), (29, 'A'), (30, ')'), (31, 'U'), (32, 'ö'), (33, '0'), (34, 'v'), (35, 'á'), (36, 'É'), (37, '/'), (38, ':'), (39, 'Z'), (40, '.'), (41, 'O'), (42, 'ó'), (43, '8'), (44, '5'), (45, 'P'), (46, 'æ'), (47, 'ë'), (48, 'z'), (49, 'V'), (50, 'x'), (51, 'k'), (52, 'N'), (53, '\\n'), (54, '”'), (55, 'T'), (56, 'ç'), (57, 'C'), (58, 'n'), (59, 'y'), (60, 'è'), (61, '“'), (62, 'ú'), (63, '7'), (64, 'S'), (65, 'p'), (66, ','), (67, 'Y'), (68, 'K'), (69, 'E'), (70, 'î'), (71, 'i'), (72, 'u'), (73, '—'), (74, 'm'), (75, 'é'), (76, '‘'), (77, 'ê'), (78, 'X'), (79, '?'), (80, 'f'), (81, ';'), (82, 'Q'), (83, 'g'), (84, 'ä'), (85, 'R'), (86, 'a'), (87, ' '), (88, 'Á'), (89, 'À'), (90, 'ü'), (91, '-'), (92, 'o'), (93, '!'), (94, 'à'), (95, '='), (96, '’'), (97, 'â'), (98, 's'), (99, 'd'), (100, '3'), (101, 'h'), (102, '*'), (103, 'G')])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["encoder = {char: ind for ind,char in decoder.items()}\n","encoded_text = np.array([encoder[char] for char in text])\n","encoded_text[:500]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cQhfOLQesUra","executionInfo":{"status":"ok","timestamp":1716841589062,"user_tz":-210,"elapsed":1132,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"9ed5956b-a8c6-4675-e58b-202d32eefbde"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 14,  29,  85,  87,  29,  52,   4,  87,  45,  69,  29,  57,  69,\n","        53,  53,  12,  41,  41,  68,  87,  41,  52,  69,  38,  87,   6,\n","        43,  33,  44,  53,  53,  53,  57,  13,  29,  45,  55,  69,  85,\n","        87,  10,  53,  53,  61,  14,   3,  11,  11,  66,  87,  45,  25,\n","        71,  58,  19,   3,  66,  87,  98,  92,  87, 103,   3,  58,  92,\n","        86,  87,  86,  58,  99,  87,  15,  72,  19,  19,  86,  87,  86,\n","        25,   3,  87,  58,  92,   0,  87,  28,  72,  98,  26,  87,  80,\n","        86,  74,  71,  11,  59,  87,   3,  98,  26,  86,  26,   3,  98,\n","        87,  92,  80,  87,  26, 101,   3,  53,  12,  72,  92,  58,  86,\n","        65,  86,  25,  26,   3,  98,  40,  87,  12,  72,  26,  87,  10,\n","        87,   0,  86,  25,  58,  87,  59,  92,  72,  66,  87,  71,  80,\n","        87,  59,  92,  72,  87,  99,  92,  58,  96,  26,  87,  26,   3,\n","        11,  11,  87,  74,   3,  87,  26, 101,  86,  26,  87,  26, 101,\n","        71,  98,  87,  74,   3,  86,  58,  98,  87,   0,  86,  25,  66,\n","        53,  71,  80,  87,  59,  92,  72,  87,  98,  26,  71,  11,  11,\n","        87,  26,  25,  59,  87,  26,  92,  87,  99,   3,  80,   3,  58,\n","        99,  87,  26, 101,   3,  87,  71,  58,  80,  86,  74,  71,   3,\n","        98,  87,  86,  58,  99,  87, 101,  92,  25,  25,  92,  25,  98,\n","        87,  65,   3,  25,  65,   3,  26,  25,  86,  26,   3,  99,  87,\n","         8,  59,  87,  26, 101,  86,  26,  53,  29,  58,  26,  71,  19,\n","       101,  25,  71,  98,  26,  73,  10,  87,  25,   3,  86,  11,  11,\n","        59,  87,   8,   3,  11,  71,   3,  34,   3,  87, 101,   3,  87,\n","        71,  98,  87,  29,  58,  26,  71,  19, 101,  25,  71,  98,  26,\n","        73,  10,  87,   0,  71,  11,  11,  87, 101,  86,  34,   3,  87,\n","        58,  92,  26, 101,  71,  58,  83,  53,  74,  92,  25,   3,  87,\n","        26,  92,  87,  99,  92,  87,   0,  71,  26, 101,  87,  59,  92,\n","        72,  87,  86,  58,  99,  87,  59,  92,  72,  87,  86,  25,   3,\n","        87,  58,  92,  87,  11,  92,  58,  83,   3,  25,  87,  74,  59,\n","        87,  80,  25,  71,   3,  58,  99,  66,  87,  58,  92,  87,  11,\n","        92,  58,  83,   3,  25,  87,  74,  59,  53,  76,  80,  86,  71,\n","        26, 101,  80,  72,  11,  87,  98,  11,  86,  34,   3,  66,  96,\n","        87,  86,  98,  87,  59,  92,  72,  87,  19,  86,  11,  11,  87,\n","        59,  92,  72,  25,  98,   3,  11,  80,  93,  87,  12,  72,  26,\n","        87, 101,  92,   0,  87,  99,  92,  87,  59,  92,  72,  87,  99,\n","        92,  79,  87,  10,  87,  98,   3,   3,  87,  10,  53, 101,  86,\n","        34,   3,  87,  80,  25,  71,  83, 101,  26,   3,  58,   3,  99,\n","        87,  59,  92,  72,  73,  98,  71,  26,  87,  99,  92,   0,  58,\n","        87,  86,  58,  99,  87,  26,   3,  11,  11,  87,  74,   3,  87,\n","        86,  11,  11,  87,  26, 101])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["# **One Hot Encoding**"],"metadata":{"id":"7HKb_vhhs3_D"}},{"cell_type":"code","source":["def one_hot_encoder(encoded_text, num_uni_chars):\n","    one_hot = np.zeros((encoded_text.size, num_uni_chars))\n","\n","    # Convert data type for later use with pytorch (errors if we dont!)\n","    one_hot = one_hot.astype(np.float32)\n","\n","    # Using indexing fill in the 1s at the correct index locations\n","    one_hot[np.arange(one_hot.shape[0]), encoded_text.flatten()] = 1.0\n","\n","\n","    # Reshape it so it matches the batch sahe\n","    one_hot = one_hot.reshape((*encoded_text.shape, num_uni_chars))\n","\n","    return one_hot"],"metadata":{"id":"8qXYQhPls58q","executionInfo":{"status":"ok","timestamp":1716841589062,"user_tz":-210,"elapsed":27,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["one_hot_encoder(np.array([1,2,0]),3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gRV-Vluthpy","executionInfo":{"status":"ok","timestamp":1716841589062,"user_tz":-210,"elapsed":25,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"81a904de-527b-4d39-e07f-35a52fd6a92b"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.]], dtype=float32)"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# **Creating Training Batches**"],"metadata":{"id":"KxsSD_aKt1uC"}},{"cell_type":"code","source":["def generate_batches(encoded_text, samp_per_batch=10, seq_len=50):\n","\n","\n","    char_per_batch = samp_per_batch * seq_len\n","\n","\n","    num_batches_avail = int(len(encoded_text)/char_per_batch)\n","\n","    encoded_text = encoded_text[:num_batches_avail * char_per_batch]\n","\n","    # Reshape text into rows the size of a batch\n","    encoded_text = encoded_text.reshape((samp_per_batch, -1))\n","\n","    for n in range(0, encoded_text.shape[1], seq_len):\n","\n","\n","        x = encoded_text[:, n:n+seq_len]\n","\n","\n","        y = np.zeros_like(x)\n","\n","\n","        try:\n","            y[:, :-1] = x[:, 1:]\n","            y[:, -1]  = encoded_text[:, n+seq_len]\n","\n","        # FOR POTENTIAL INDEXING ERROR AT THE END\n","        except:\n","            y[:, :-1] = x[:, 1:]\n","            y[:, -1] = encoded_text[:, 0]\n","\n","        yield x, y"],"metadata":{"id":"-P1vmMXat3Ja","executionInfo":{"status":"ok","timestamp":1716841589063,"user_tz":-210,"elapsed":22,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["sample_text = encoded_text[:20]\n","sample_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fxTfIl_udAT","executionInfo":{"status":"ok","timestamp":1716841589063,"user_tz":-210,"elapsed":20,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"4c9bd735-64ac-4162-ae20-2861ed5b0a85"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([14, 29, 85, 87, 29, 52,  4, 87, 45, 69, 29, 57, 69, 53, 53, 12, 41,\n","       41, 68, 87])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["batch_generator = generate_batches(sample_text,samp_per_batch=2,seq_len=5)\n","x, y = next(batch_generator)"],"metadata":{"id":"xfKQHORDuhlJ","executionInfo":{"status":"ok","timestamp":1716841589063,"user_tz":-210,"elapsed":17,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oG1GkgihukuS","executionInfo":{"status":"ok","timestamp":1716841589063,"user_tz":-210,"elapsed":16,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"d3ac7eff-2adc-4eb4-9b1c-e387c6561f21"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[14, 29, 85, 87, 29],\n","       [29, 57, 69, 53, 53]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YQSIfRy-ul9J","executionInfo":{"status":"ok","timestamp":1716841589063,"user_tz":-210,"elapsed":12,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"2ed7b1a2-5d0b-4b15-9f6d-d2dca5afe2c3"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[29, 85, 87, 29, 52],\n","       [57, 69, 53, 53, 12]])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UkkVUddiuocf","executionInfo":{"status":"ok","timestamp":1716841589064,"user_tz":-210,"elapsed":9,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"79b1a99f-2746-4a0f-efcc-3ce3d803c020"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["# **Creating the LSTM Model**"],"metadata":{"id":"yz8se0Kgu81P"}},{"cell_type":"code","source":["class CharModel(nn.Module):\n","\n","    def __init__(self, all_chars, num_hidden=256, num_layers=4,drop_prob=0.5,use_gpu=True):\n","\n","\n","        # SET UP ATTRIBUTES\n","        super().__init__()\n","        self.drop_prob = drop_prob\n","        self.num_layers = num_layers\n","        self.num_hidden = num_hidden\n","        self.use_gpu = use_gpu\n","\n","        #CHARACTER SET, ENCODER, and DECODER\n","        self.all_chars = all_chars\n","        self.decoder = dict(enumerate(all_chars))\n","        self.encoder = {char: ind for ind,char in decoder.items()}\n","\n","\n","        self.lstm = nn.LSTM(len(self.all_chars), num_hidden, num_layers, dropout=drop_prob, batch_first=True)\n","\n","        self.dropout = nn.Dropout(drop_prob)\n","\n","        self.fc_linear = nn.Linear(num_hidden, len(self.all_chars))\n","\n","\n","    def forward(self, x, hidden):\n","\n","\n","        lstm_output, hidden = self.lstm(x, hidden)\n","\n","\n","        drop_output = self.dropout(lstm_output)\n","\n","        drop_output = drop_output.contiguous().view(-1, self.num_hidden)\n","\n","\n","        final_out = self.fc_linear(drop_output)\n","\n","\n","        return final_out, hidden\n","\n","\n","    def hidden_state(self, batch_size):\n","        '''\n","        Used as separate method to account for both GPU and CPU users.\n","        '''\n","\n","        if self.use_gpu:\n","\n","            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda(),\n","                     torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda())\n","        else:\n","            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden),\n","                     torch.zeros(self.num_layers,batch_size,self.num_hidden))\n","\n","        return hidden\n",""],"metadata":{"id":"qEo_KkNnu57P","executionInfo":{"status":"ok","timestamp":1716841696493,"user_tz":-210,"elapsed":526,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["model = CharModel(\n","    all_chars=all_characters,\n","    num_hidden=512,\n","    num_layers=3,\n","    drop_prob=0.5,\n","    use_gpu=True,\n",")\n","total_param  = []\n","for p in model.parameters():\n","    total_param.append(int(p.numel()))"],"metadata":{"id":"l6kCas9Zvcbn","executionInfo":{"status":"ok","timestamp":1716841758783,"user_tz":-210,"elapsed":6,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["len(encoded_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvFwA2DQvme7","executionInfo":{"status":"ok","timestamp":1716841771557,"user_tz":-210,"elapsed":5,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"41c181ba-50a3-41d2-8095-62b1cbb1154c"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3201623"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["# **training Data and Validation Data**"],"metadata":{"id":"e9vVhsyrvpP6"}},{"cell_type":"code","source":["optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","train_percent = 0.1\n","train_ind = int(len(encoded_text) * (train_percent))\n","train_data = encoded_text[:train_ind]\n","val_data = encoded_text[train_ind:]"],"metadata":{"id":"zqt4YLMrvsv6","executionInfo":{"status":"ok","timestamp":1716841855788,"user_tz":-210,"elapsed":1793,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["epochs = 50\n","# batch size\n","batch_size = 128\n","\n","# Length of sequence\n","seq_len = 100\n","\n","# for printing report purposes\n","# always start at 0\n","tracker = 0\n","\n","# number of characters in text\n","num_char = max(encoded_text)+1"],"metadata":{"id":"aHFAg07Gv9p6","executionInfo":{"status":"ok","timestamp":1716841885914,"user_tz":-210,"elapsed":557,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["model.train()\n","\n","\n","if model.use_gpu:\n","    model.cuda()\n","\n","for i in range(epochs):\n","\n","    hidden = model.hidden_state(batch_size)\n","\n","\n","    for x,y in generate_batches(train_data,batch_size,seq_len):\n","\n","        tracker += 1\n","\n","        # One Hot Encode incoming data\n","        x = one_hot_encoder(x,num_char)\n","\n","        # Convert Numpy Arrays to Tensor\n","\n","        inputs = torch.from_numpy(x)\n","        targets = torch.from_numpy(y)\n","\n","\n","        if model.use_gpu:\n","\n","            inputs = inputs.cuda()\n","            targets = targets.cuda()\n","\n","        # Reset Hidden State\n","\n","        hidden = tuple([state.data for state in hidden])\n","\n","        model.zero_grad()\n","\n","        lstm_output, hidden = model.forward(inputs,hidden)\n","        loss = criterion(lstm_output,targets.view(batch_size*seq_len).long())\n","\n","        loss.backward()\n","\n","\n","        nn.utils.clip_grad_norm_(model.parameters(),max_norm=5)\n","\n","        optimizer.step()\n","\n","        if tracker % 25 == 0:\n","\n","            val_hidden = model.hidden_state(batch_size)\n","            val_losses = []\n","            model.eval()\n","\n","            for x,y in generate_batches(val_data,batch_size,seq_len):\n","\n","                # One Hot Encode incoming data\n","                x = one_hot_encoder(x,num_char)\n","\n","\n","                # Convert Numpy Arrays to Tensor\n","\n","                inputs = torch.from_numpy(x)\n","                targets = torch.from_numpy(y)\n","\n","                # Adjust for GPU if necessary\n","\n","                if model.use_gpu:\n","\n","                    inputs = inputs.cuda()\n","                    targets = targets.cuda()\n","\n","                # Reset Hidden State\n","\n","                val_hidden = tuple([state.data for state in val_hidden])\n","\n","                lstm_output, val_hidden = model.forward(inputs,val_hidden)\n","                val_loss = criterion(lstm_output,targets.view(batch_size*seq_len).long())\n","\n","                val_losses.append(val_loss.item())\n","\n","            # Reset to training model after val for loop\n","            model.train()\n","\n","            print(f\"Epoch: {i} Step: {tracker} Val Loss: {val_loss.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdQiM6XUwFRj","executionInfo":{"status":"ok","timestamp":1716842655322,"user_tz":-210,"elapsed":726728,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"69a8f2f6-882b-41dc-aa4c-094190cfdf1d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 Step: 25 Val Loss: 3.111769199371338\n","Epoch: 1 Step: 50 Val Loss: 3.1074059009552\n","Epoch: 2 Step: 75 Val Loss: 3.1050972938537598\n","Epoch: 3 Step: 100 Val Loss: 3.102761745452881\n","Epoch: 4 Step: 125 Val Loss: 3.0381548404693604\n","Epoch: 5 Step: 150 Val Loss: 2.8327789306640625\n","Epoch: 6 Step: 175 Val Loss: 2.727395534515381\n","Epoch: 7 Step: 200 Val Loss: 2.5607335567474365\n","Epoch: 8 Step: 225 Val Loss: 2.401561975479126\n","Epoch: 9 Step: 250 Val Loss: 2.3219122886657715\n","Epoch: 10 Step: 275 Val Loss: 2.253509283065796\n","Epoch: 11 Step: 300 Val Loss: 2.2053675651550293\n","Epoch: 12 Step: 325 Val Loss: 2.1483190059661865\n","Epoch: 13 Step: 350 Val Loss: 2.099440574645996\n","Epoch: 14 Step: 375 Val Loss: 2.05193829536438\n","Epoch: 15 Step: 400 Val Loss: 2.005499839782715\n","Epoch: 16 Step: 425 Val Loss: 1.9708747863769531\n","Epoch: 17 Step: 450 Val Loss: 1.9347240924835205\n","Epoch: 18 Step: 475 Val Loss: 1.9007033109664917\n","Epoch: 19 Step: 500 Val Loss: 1.8734513521194458\n","Epoch: 20 Step: 525 Val Loss: 1.846662998199463\n","Epoch: 21 Step: 550 Val Loss: 1.8200736045837402\n","Epoch: 22 Step: 575 Val Loss: 1.796481728553772\n","Epoch: 23 Step: 600 Val Loss: 1.7750844955444336\n","Epoch: 24 Step: 625 Val Loss: 1.7531683444976807\n","Epoch: 25 Step: 650 Val Loss: 1.737266182899475\n","Epoch: 26 Step: 675 Val Loss: 1.7203401327133179\n","Epoch: 27 Step: 700 Val Loss: 1.6990957260131836\n","Epoch: 28 Step: 725 Val Loss: 1.6836296319961548\n","Epoch: 29 Step: 750 Val Loss: 1.6749149560928345\n","Epoch: 30 Step: 775 Val Loss: 1.664413571357727\n","Epoch: 31 Step: 800 Val Loss: 1.6451258659362793\n","Epoch: 32 Step: 825 Val Loss: 1.6407546997070312\n","Epoch: 33 Step: 850 Val Loss: 1.6335933208465576\n","Epoch: 34 Step: 875 Val Loss: 1.6166797876358032\n","Epoch: 35 Step: 900 Val Loss: 1.6064289808273315\n","Epoch: 36 Step: 925 Val Loss: 1.599595546722412\n","Epoch: 37 Step: 950 Val Loss: 1.5938143730163574\n","Epoch: 38 Step: 975 Val Loss: 1.585504412651062\n","Epoch: 39 Step: 1000 Val Loss: 1.576858639717102\n","Epoch: 40 Step: 1025 Val Loss: 1.5757635831832886\n","Epoch: 41 Step: 1050 Val Loss: 1.5655566453933716\n","Epoch: 42 Step: 1075 Val Loss: 1.5596718788146973\n","Epoch: 43 Step: 1100 Val Loss: 1.5566411018371582\n","Epoch: 44 Step: 1125 Val Loss: 1.554465889930725\n","Epoch: 45 Step: 1150 Val Loss: 1.5461299419403076\n","Epoch: 46 Step: 1175 Val Loss: 1.543116569519043\n","Epoch: 47 Step: 1200 Val Loss: 1.5398122072219849\n","Epoch: 48 Step: 1225 Val Loss: 1.538680076599121\n","Epoch: 49 Step: 1250 Val Loss: 1.5369845628738403\n"]}]},{"cell_type":"code","source":["model_name = 'example.net'\n","torch.save(model.state_dict(),model_name)"],"metadata":{"id":"f7MaSFluzRqD","executionInfo":{"status":"ok","timestamp":1716842744905,"user_tz":-210,"elapsed":8,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"Rbgo2iCuzXEC"}},{"cell_type":"code","source":["\n","model = CharModel(\n","    all_chars=all_characters,\n","    num_hidden=512,\n","    num_layers=3,\n","    drop_prob=0.5,\n","    use_gpu=True,\n",")"],"metadata":{"id":"Eb_zYBUNzTS6","executionInfo":{"status":"ok","timestamp":1716842768525,"user_tz":-210,"elapsed":661,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load(model_name))\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BmO6dNG2zcB4","executionInfo":{"status":"ok","timestamp":1716842777583,"user_tz":-210,"elapsed":10,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"eb88fdec-a185-4608-91e0-319e8af184f9"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CharModel(\n","  (lstm): LSTM(104, 512, num_layers=3, batch_first=True, dropout=0.5)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc_linear): Linear(in_features=512, out_features=104, bias=True)\n",")"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["generate prediction"],"metadata":{"id":"rOdPgm-Tzff_"}},{"cell_type":"code","source":["def predict_next_char(model, char, hidden=None, k=1):\n","\n","\n","        encoded_text = model.encoder[char]\n","\n","        encoded_text = np.array([[encoded_text]])\n","\n","        encoded_text = one_hot_encoder(encoded_text, len(model.all_chars))\n","\n","        inputs = torch.from_numpy(encoded_text)\n","\n","        # Check for CPU\n","        if(model.use_gpu):\n","            inputs = inputs.cuda()\n","\n","\n","        hidden = tuple([state.data for state in hidden])\n","\n","\n","        lstm_out, hidden = model(inputs, hidden)\n","\n","\n","        probs = F.softmax(lstm_out, dim=1).data\n","\n","\n","        if(model.use_gpu):\n","            # move back to CPU to use with numpy\n","            probs = probs.cpu()\n","\n","\n","        probs, index_positions = probs.topk(k)\n","\n","\n","        index_positions = index_positions.numpy().squeeze()\n","\n","        probs = probs.numpy().flatten()\n","\n","\n","        probs = probs/probs.sum()\n","\n","        char = np.random.choice(index_positions, p=probs)\n","\n","        # return the encoded value of the predicted char and the hidden state\n","        return model.decoder[char], hidden"],"metadata":{"id":"nPDEuGipzhv7","executionInfo":{"status":"ok","timestamp":1716842839651,"user_tz":-210,"elapsed":554,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def generate_text(model, size, seed='The', k=1):\n","\n","\n","\n","    # CHECK FOR GPU\n","    if(model.use_gpu):\n","        model.cuda()\n","    else:\n","        model.cpu()\n","\n","    # Evaluation mode\n","    model.eval()\n","\n","    # begin output from initial seed\n","    output_chars = [c for c in seed]\n","\n","    # intiate hidden state\n","    hidden = model.hidden_state(1)\n","\n","    # predict the next character for every character in seed\n","    for char in seed:\n","        char, hidden = predict_next_char(model, char, hidden, k=k)\n","\n","    # add initial characters to output\n","    output_chars.append(char)\n","\n","    # Now generate for size requested\n","    for i in range(size):\n","\n","        # predict based off very last letter in output_chars\n","        char, hidden = predict_next_char(model, output_chars[-1], hidden, k=k)\n","\n","        # add predicted character\n","        output_chars.append(char)\n","\n","    # return string of predicted text\n","    return ''.join(output_chars)"],"metadata":{"id":"Epy8Jc8tzuDM","executionInfo":{"status":"ok","timestamp":1716842889127,"user_tz":-210,"elapsed":537,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["print(generate_text(model, 1000, seed='Buonaparte ', k=3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUiDHjIPzxhS","executionInfo":{"status":"ok","timestamp":1716843437916,"user_tz":-210,"elapsed":1014,"user":{"displayName":"شادمهر 003","userId":"05469703983428230705"}},"outputId":"b14d137a-c5e3-40f2-f6b0-f3d4ec06cfd5"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Buonaparte with a smile. He hoped and should the song of the same countess as a store soldiers.\n","\n","“What it as you were a good man as if the service of a service and so than the count’s head and the considerions that have a senere mentions to be tolding that him a beauty as the women.... In a should only began and think, the prince was to see that the window, and that all to this\n","in to say, but\n","the prevertion and that it is all all still there any one affeed out of the same sign of the count’s, but it is all so the will of the count at\n","the carriage to he said. The presence of the story.\n","\n","Anna Pávlovna wished to say an aid of the day, which showed him.\n","\n","“And the presence madated, but you are all something,” said the countess, was\n","all that they and the count as the pretion, and she was a bold, and stoping time, the same strange of the count and\n","have the canter as an expression of the door on the dineralth and taking him. The count was silent, and starting at his strange of a smiling room. “And I have \n"]}]}]}